{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model - Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "random.seed(10)\n",
    "ad =  pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a glimpse at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>MRI ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR1</td>\n",
       "      <td>Demented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR2</td>\n",
       "      <td>Demented</td>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR3</td>\n",
       "      <td>Demented</td>\n",
       "      <td>3</td>\n",
       "      <td>1895</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
       "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
       "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
       "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
       "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
       "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
       "\n",
       "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
       "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
       "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
       "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
       "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
       "4  NaN  22.0  0.5  1698  0.701  1.034  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping CDR 2.0 to 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.loc[ad[\"CDR\"] == 2,\"CDR\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad[\"Male\"] = np.where(ad[\"M/F\"]==\"M\", 1, 0)\n",
    "ad[\"Female\"] = np.where(ad[\"M/F\"]==\"F\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the columns into indepdent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ad.iloc[:,[3,4,7,8,9,10,11,12,13,14]]\n",
    "y = ad.iloc[:,[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_X_train, ad_X_test, ad_y_train, ad_y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_SES = ad_X_train['SES'].mean()\n",
    "avg_MMSE = ad_X_train['MMSE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_X_train.loc[:,'SES'] = ad_X_train.loc[:,'SES'].fillna(med_SES)\n",
    "ad_X_train.loc[:,'MMSE'] = ad_X_train.loc[:,'MMSE'].fillna(avg_MMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_X_test[\"Group\"] = ad_y_test\n",
    "ad_X_test = ad_X_test.dropna(axis = 0, how='any')\n",
    "\n",
    "ad_y_test = ad_X_test[\"Group\"]\n",
    "ad_X_test=ad_X_test.loc[:,ad_X_test.columns!='Group']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the function to check the accuracy, precision, and recall scores for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_test(cnt,fold):\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits=fold, random_state=None)\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    acc_score = []\n",
    "    precise_score = []\n",
    "    recall = []\n",
    "    for train_index, test_index in kf.split(ad_X_train):\n",
    "        X_train, X_test = ad_X_train.iloc[train_index,:], ad_X_train.iloc[test_index,:]\n",
    "        y_train, y_test = ad_y_train.iloc[train_index,:], ad_y_train.iloc[test_index,:]\n",
    "\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        X_test=X_test.loc[:,X_test.columns!='Group']\n",
    "\n",
    "        if cnt < 9:\n",
    "            clf1 = tree.DecisionTreeClassifier().fit(X_train,y_train)\n",
    "\n",
    "            sfs_forward = SequentialFeatureSelector(\n",
    "            clf1 , n_features_to_select = cnt, direction = \"forward\").fit(X_train,y_train)\n",
    "\n",
    "\n",
    "            clf.fit(X_train[X_train.columns[sfs_forward.get_support()]],y_train)\n",
    "\n",
    "            y_pred = clf.predict(ad_X_test[ad_X_test.columns[sfs_forward.get_support()]])\n",
    "        else:\n",
    "            clf.fit(X_train,y_train)\n",
    "            y_pred = clf.predict(ad_X_test)\n",
    "\n",
    "\n",
    "        acc = accuracy_score(ad_y_test, y_pred)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "        precise = precision_score(ad_y_test, y_pred, average='macro',zero_division=1)\n",
    "        precise_score.append(precise)\n",
    "\n",
    "        rec = recall_score(ad_y_test, y_pred, average = 'macro', zero_division = 1)\n",
    "        recall.append(rec)        \n",
    "        \n",
    "    return acc_score, precise_score, recall\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting One Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.4934579439252336\n",
      "0.43644859813084114\n",
      "0.432398753894081\n",
      "0.43224299065420557\n",
      "0.4328971962616822\n",
      "The average of the accuracy score:  0.4454890965732087\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.4525761237946558\n",
      "0.3701092348220678\n",
      "0.36576040839884066\n",
      "0.36562323068864633\n",
      "0.3670207025890472\n",
      "The average of the precision score:  0.3842179400586515\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.42406414723487895\n",
      "0.36911015813454834\n",
      "0.3653444116858751\n",
      "0.3640556597873671\n",
      "0.36566872152238006\n",
      "The average of the recall score:  0.3776486196730099\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(1,5)\n",
    "a10 = acc_test(1,10)\n",
    "a15 = acc_test(1,15)\n",
    "a20 = acc_test(1,20)\n",
    "a25 = acc_test(1,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc1 = (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc1)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre1 =  (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "print(\"The average of the precision score: \", pre1)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec1 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "\n",
    "print(\"The average of the recall score: \", rec1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Two Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.7757009345794392\n",
      "0.7728971962616822\n",
      "0.7713395638629283\n",
      "0.7672897196261682\n",
      "0.7708411214953271\n",
      "The average of the accuracy score:  0.771613707165109\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.5987192450052431\n",
      "0.6066505577027904\n",
      "0.6100884636305124\n",
      "0.5968845745768614\n",
      "0.6053370279547322\n",
      "The average of the precision score:  0.6035359737740279\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.6096444206200303\n",
      "0.614337085678549\n",
      "0.6173218380535453\n",
      "0.6045731707317074\n",
      "0.6127124095416778\n",
      "The average of the recall score:  0.611717784925102\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(2,5)\n",
    "a10 = acc_test(2,10)\n",
    "a15 = acc_test(2,15)\n",
    "a20 = acc_test(2,20)\n",
    "a25 = acc_test(2,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc2 =  (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc2)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre2 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "\n",
    "print(\"The average of the precision score: \", pre2)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec2 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "print(\"The average of the recall score: \", rec2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Three Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.8186915887850467\n",
      "0.808411214953271\n",
      "0.8049844236760124\n",
      "0.8060747663551402\n",
      "0.8157009345794393\n",
      "The average of the accuracy score:  0.8107725856697818\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.6874490421858842\n",
      "0.6668602532745806\n",
      "0.6717866615514053\n",
      "0.6745687000174041\n",
      "0.6911113063928659\n",
      "The average of the precision score:  0.678355192684428\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.6798177432323774\n",
      "0.669822657017779\n",
      "0.6643869680455047\n",
      "0.6652461359778433\n",
      "0.6800607522558743\n",
      "The average of the recall score:  0.6718668513058758\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(3,5)\n",
    "a10 = acc_test(3,10)\n",
    "a15 = acc_test(3,15)\n",
    "a20 = acc_test(3,20)\n",
    "a25 = acc_test(3,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc3 =  (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc3)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre3 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "\n",
    "print(\"The average of the precision score: \", pre3)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec3 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "print(\"The average of the recall score: \", rec3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Four Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.82803738317757\n",
      "0.8168224299065421\n",
      "0.8193146417445483\n",
      "0.8107476635514018\n",
      "0.8183177570093457\n",
      "The average of the accuracy score:  0.8186479750778816\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.7103073799367638\n",
      "0.6949142490875204\n",
      "0.6908928816259496\n",
      "0.6968701692245273\n",
      "0.6945832127256399\n",
      "The average of the precision score:  0.6975135785200803\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.7029393370856786\n",
      "0.6901992316626463\n",
      "0.6872048006194348\n",
      "0.6915963101938711\n",
      "0.6874153488787635\n",
      "The average of the recall score:  0.6918710056880789\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(4,5)\n",
    "a10 = acc_test(4,10)\n",
    "a15 = acc_test(4,15)\n",
    "a20 = acc_test(4,20)\n",
    "a25 = acc_test(4,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc4 =  (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc4)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre4 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "print(\"The average of the precision score: \", pre4)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec4 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "print(\"The average of the recall score: \", rec4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Five Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.8093457943925233\n",
      "0.8177570093457944\n",
      "0.8180685358255452\n",
      "0.8144859813084112\n",
      "0.8235514018691589\n",
      "The average of the accuracy score:  0.8166417445482865\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.6701319191118302\n",
      "0.6903187494789175\n",
      "0.6992532920807204\n",
      "0.6911164293527504\n",
      "0.7043316648906249\n",
      "The average of the precision score:  0.6910304109829688\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.6636558563387832\n",
      "0.6843964978111319\n",
      "0.6929658417463296\n",
      "0.6825828642901813\n",
      "0.6956624676136871\n",
      "The average of the recall score:  0.6838527055600225\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(5,5)\n",
    "a10 = acc_test(5,10)\n",
    "a15 = acc_test(5,15)\n",
    "a20 = acc_test(5,20)\n",
    "a25 = acc_test(5,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc5 = (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc5)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre5 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "print(\"The average of the precision score: \", pre5)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec5 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "print(\"The average of the recall score: \", rec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Six Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.8448598130841122\n",
      "0.8252336448598131\n",
      "0.8199376947040499\n",
      "0.8247663551401869\n",
      "0.8239252336448598\n",
      "The average of the accuracy score:  0.8277445482866044\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.7471513196362356\n",
      "0.7037445220739474\n",
      "0.7072113773596124\n",
      "0.7130918991555069\n",
      "0.7079214526925348\n",
      "The average of the precision score:  0.7158241141835674\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.7224291968194407\n",
      "0.6943804163316358\n",
      "0.6999195926025195\n",
      "0.7085913070669169\n",
      "0.6971732332707943\n",
      "The average of the recall score:  0.7044987492182614\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(6,5)\n",
    "a10 = acc_test(6,10)\n",
    "a15 = acc_test(6,15)\n",
    "a20 = acc_test(6,20)\n",
    "a25 = acc_test(6,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc6 = (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc6)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre6 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "print(\"The average of the precision score: \", pre6)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec6 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "print(\"The average of the recall score: \", rec6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Seven Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.8523364485981308\n",
      "0.8336448598130841\n",
      "0.8292834890965732\n",
      "0.8303738317757009\n",
      "0.8302803738317757\n",
      "The average of the accuracy score:  0.835183800623053\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.7545177832924994\n",
      "0.730427441024788\n",
      "0.7195451496379875\n",
      "0.7175981167426561\n",
      "0.7262562012619457\n",
      "The average of the precision score:  0.7296689383919753\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.7202537300098275\n",
      "0.7144130259983918\n",
      "0.7071324339617022\n",
      "0.7051237380505673\n",
      "0.7112757973733583\n",
      "The average of the recall score:  0.7116397450787695\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(7,5)\n",
    "a10 = acc_test(7,10)\n",
    "a15 = acc_test(7,15)\n",
    "a20 = acc_test(7,20)\n",
    "a25 = acc_test(7,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc7 = (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc7 )\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre7 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "print(\"The average of the precision score: \", pre7)\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec7 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "print(\"The average of the recall score: \", rec7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Eight Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.8411214953271028\n",
      "0.8345794392523365\n",
      "0.8305295950155763\n",
      "0.8327102803738318\n",
      "0.84\n",
      "The average of the accuracy score:  0.8357881619937695\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.7451781200127453\n",
      "0.7305191645045799\n",
      "0.7208531110303593\n",
      "0.7258390627523624\n",
      "0.738022393644029\n",
      "The average of the precision score:  0.7320823703888152\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.7090815688376664\n",
      "0.7187058876083267\n",
      "0.7137868906161589\n",
      "0.7175098275708032\n",
      "0.7239837398373984\n",
      "The average of the recall score:  0.7166135828940707\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(8,5)\n",
    "a10 = acc_test(8,10)\n",
    "a15 = acc_test(8,15)\n",
    "a20 = acc_test(8,20)\n",
    "a25 = acc_test(8,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc8 = (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc8 )\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre8 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "print(\"The average of the precision score: \", pre8 )\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec8 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "print(\"The average of the recall score: \", rec8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Nine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "0.8448598130841122\n",
      "0.8420560747663551\n",
      "0.8367601246105919\n",
      "0.8378504672897196\n",
      "0.8306542056074766\n",
      "The average of the accuracy score:  0.8384361370716512\n",
      "*******************************\n",
      "Precision Scores\n",
      "0.7430806861814614\n",
      "0.7416987794389482\n",
      "0.7360560795196723\n",
      "0.7346206963003328\n",
      "0.7293262991051992\n",
      "The average of the precision score:  0.7369565081091228\n",
      "*******************************\n",
      "Recall Scores\n",
      "0.7210533369069955\n",
      "0.7273139462163852\n",
      "0.7180603948896632\n",
      "0.7261692575716966\n",
      "0.7221093540605735\n",
      "The average of the recall score:  0.7229412579290628\n"
     ]
    }
   ],
   "source": [
    "a5 = acc_test(9,5)\n",
    "a10 = acc_test(9,10)\n",
    "a15 = acc_test(9,15)\n",
    "a20 = acc_test(9,20)\n",
    "a25 = acc_test(9,25)\n",
    "\n",
    "a5_acc = stat.mean(a5[0])\n",
    "a10_acc = stat.mean(a10[0])\n",
    "a15_acc = stat.mean(a15[0])\n",
    "a20_acc = stat.mean(a20[0])\n",
    "a25_acc = stat.mean(a25[0])\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(a5_acc)\n",
    "print(a10_acc)\n",
    "print(a15_acc)\n",
    "print(a20_acc)\n",
    "print(a25_acc)\n",
    "\n",
    "acc9 = (a5_acc + a10_acc + a15_acc + a20_acc + a25_acc) / 5\n",
    "\n",
    "print(\"The average of the accuracy score: \", acc9 )\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Precision Scores\")\n",
    "a5_prec = stat.mean(a5[1])\n",
    "a10_prec = stat.mean(a10[1])\n",
    "a15_prec = stat.mean(a15[1])\n",
    "a20_prec = stat.mean(a20[1])\n",
    "a25_prec = stat.mean(a25[1])\n",
    "\n",
    "print(a5_prec)\n",
    "print(a10_prec)\n",
    "print(a15_prec)\n",
    "print(a20_prec)\n",
    "print(a25_prec)\n",
    "\n",
    "pre9 = (a5_prec + a10_prec + a15_prec + a20_prec + a25_prec) / 5\n",
    "\n",
    "print(\"The average of the precision score: \", pre9 )\n",
    "\n",
    "print(\"*******************************\")\n",
    "print(\"Recall Scores\")\n",
    "a5_rec = stat.mean(a5[2])\n",
    "a10_rec = stat.mean(a10[2])\n",
    "a15_rec = stat.mean(a15[2])\n",
    "a20_rec = stat.mean(a20[2])\n",
    "a25_rec = stat.mean(a25[2])\n",
    "\n",
    "print(a5_rec)\n",
    "print(a10_rec)\n",
    "print(a15_rec)\n",
    "print(a20_rec)\n",
    "print(a25_rec)\n",
    "\n",
    "rec9 = (a5_rec + a10_rec + a15_rec + a20_rec + a25_rec) / 5\n",
    "\n",
    "print(\"The average of the recall score: \", rec9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score\n",
      "Selection One Feature:  0.4454890965732087\n",
      "Selection Two Features:  0.771613707165109\n",
      "Selection Three Features:  0.8107725856697818\n",
      "Selection Four Features:  0.8186479750778816\n",
      "Selection Five Features:  0.8166417445482865\n",
      "Selection Six Features:  0.8277445482866044\n",
      "Selection Seven Features:  0.835183800623053\n",
      "Selection Eight Features:  0.8357881619937695\n",
      "Selection Nine Features:  0.8384361370716512\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\")\n",
    "print(\"Selection One Feature: \", acc1)\n",
    "print(\"Selection Two Features: \", acc2)\n",
    "print(\"Selection Three Features: \", acc3)\n",
    "print(\"Selection Four Features: \", acc4)\n",
    "print(\"Selection Five Features: \", acc5)\n",
    "print(\"Selection Six Features: \", acc6)\n",
    "print(\"Selection Seven Features: \", acc7)\n",
    "print(\"Selection Eight Features: \", acc8)\n",
    "print(\"Selection Nine Features: \", acc9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score\n",
      "Selection One Feature:  0.3842179400586515\n",
      "Selection Two Features:  0.6035359737740279\n",
      "Selection Three Features:  0.678355192684428\n",
      "Selection Four Features:  0.6975135785200803\n",
      "Selection Five Features:  0.6910304109829688\n",
      "Selection Six Features:  0.7158241141835674\n",
      "Selection Seven Features:  0.7296689383919753\n",
      "Selection Eight Features:  0.7320823703888152\n",
      "Selection Nine Features:  0.7369565081091228\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision Score\")\n",
    "print(\"Selection One Feature: \", pre1)\n",
    "print(\"Selection Two Features: \", pre2)\n",
    "print(\"Selection Three Features: \", pre3)\n",
    "print(\"Selection Four Features: \", pre4)\n",
    "print(\"Selection Five Features: \", pre5)\n",
    "print(\"Selection Six Features: \", pre6)\n",
    "print(\"Selection Seven Features: \", pre7)\n",
    "print(\"Selection Eight Features: \", pre8)\n",
    "print(\"Selection Nine Features: \", pre9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Selection One Feature:  0.3776486196730099\n",
      "Selection Two Features:  0.611717784925102\n",
      "Selection Three Features:  0.6718668513058758\n",
      "Selection Four Features:  0.6918710056880789\n",
      "Selection Five Features:  0.6838527055600225\n",
      "Selection Six Features:  0.7044987492182614\n",
      "Selection Seven Features:  0.7116397450787695\n",
      "Selection Eight Features:  0.7166135828940707\n",
      "Selection Nine Features:  0.7229412579290628\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score\")\n",
    "print(\"Selection One Feature: \", rec1)\n",
    "print(\"Selection Two Features: \", rec2)\n",
    "print(\"Selection Three Features: \", rec3)\n",
    "print(\"Selection Four Features: \", rec4)\n",
    "print(\"Selection Five Features: \", rec5)\n",
    "print(\"Selection Six Features: \", rec6)\n",
    "print(\"Selection Seven Features: \", rec7)\n",
    "print(\"Selection Eight Features: \", rec8)\n",
    "print(\"Selection Nine Features: \", rec9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Visit', 'MR Delay', 'EDUC', 'SES', 'CDR', 'ASF'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "med_SES = stat.median(X['SES'])\n",
    "avg_MMSE = X['MMSE'].mean()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.loc[:,'SES'] = X_train.loc[:,'SES'].fillna(med_SES)\n",
    "X_train.loc[:,'MMSE'] = X_train.loc[:,'MMSE'].fillna(avg_MMSE)\n",
    "\n",
    "X_test[\"Group\"] = y_test\n",
    "X_test = X_test.dropna(axis = 0, how='any')\n",
    "\n",
    "y_test = X_test[\"Group\"]\n",
    "X_test=X_test.loc[:,X_test.columns!='Group']\n",
    "\n",
    "clf1 = tree.DecisionTreeClassifier().fit(X_train,y_train)\n",
    "\n",
    "sfs_forward = SequentialFeatureSelector(\n",
    "clf1 , n_features_to_select = 6, direction = \"forward\").fit(X_train,y_train)\n",
    "\n",
    "X_test.columns[sfs_forward.get_support()]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1149b4cf27a6be64942d6349e5d3a5a390f7bc340efac3803b90f8137d94e5d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
